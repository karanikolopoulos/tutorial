{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ch_karanikolopoulos/miniconda3/envs/thesis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "_ = load_dotenv()\n",
    "\n",
    "def collect() -> None:\n",
    "    import gc\n",
    "    gc.collect() # garbage collector\n",
    "    torch.cuda.empty_cache() # updates nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        use_safetensors=True,\n",
    "        device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id, use_safetensors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who is agent 005? Answer in one sentence.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I couldn't find any information on a well-known character or agent named \"Agent 005.\" However, there is a character named \"Number 5\" or \"Agent 005\" in the 1967 James Bond film \"You Only Live Twice,\" played by actor Donald Pleasence, but he is actually known as \"Kissy Suzuki's\" brother and a Japanese agent.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Who is agent 005? Answer in one sentence.\"}\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    conversation=conversation,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    )\n",
    "\n",
    "gen_text = tokenizer.decode(gen_tokens[0])\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "del model; collect()\n",
    "\n",
    "model_id = \"CohereForAI/c4ai-command-r-v01-4bit\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        use_safetensors=True,\n",
    "        device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id, use_safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Who is agent 005? Answer in one sentence.<|END_OF_TURN_TOKEN|>Agent 005 is a character in the James Bond series and is one of MI6's agents, but his role is often overshadowed by Bond's missions.<|END_OF_TURN_TOKEN|>\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.apply_chat_template(\n",
    "    conversation=conversation,\n",
    "    chat_template=\"default\",\n",
    "    return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    )\n",
    "\n",
    "gen_text = tokenizer.decode(gen_tokens[0])\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Documents: 0,1\n",
      "Cited Documents: 0,1\n",
      "Grounded answer: Agent 005 is either <co: 0>Duffy Duck</co: 0>, who works alongside <co: 0>007</co: 0> at the <co: 0>Monaco Casino</co: 0>, or <co: 1>Bugs Bunny</co: 1>, who foils schemes in <co: 1>Havana.</co: 1><|END_OF_TURN_TOKEN|>\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    {\n",
    "        \"title\": \"License to Quack\", \n",
    "        \"text\": (\n",
    "            \"Agent 005, Duffy Duck, adjusted his bow tie as he waddled into the Monaco Casino, his webbed feet barely making a sound.\\n\"\n",
    "            \"Across the room, Jacques “The Feather” Plume sat with his pet falcon, unaware his microchip smuggling operation was about to be quacked.\\n\"\n",
    "            \"Unlike his suave colleague, 007, Duffy wasn’t one for martinis or smooth one-liners—he preferred action.\\n\"\n",
    "            \"As his gadget-packed cufflink magnetized the chip from the falcon’s beak mid-distraction, he smirked.\\n\"\n",
    "            \"“Move over, Bond,” he muttered, slipping out as chaos erupted. “The world’s got room for one more double-zero.”\"\n",
    "            )\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Carrot Confidential\",\n",
    "        \"text\": (\n",
    "            \"Agent 005, Bugs Bunny, lounged casually in a Havana cigar bar, nibbling a carrot as he waited for Dr. Harebrained,\\n\"\n",
    "            \"the notorious inventor plotting to flood the market with mind-controlling chewing gum.\\n\"\n",
    "            \"When the villain finally appeared, Bugs tipped his fedora and muttered, “Eh, what’s up, Doc?” before slipping a tracker into Harebrained’s pocket with a sleight of hand.\\n\"\n",
    "            \"Moments later, chaos erupted as Bugs activated a remote that detonated every stick of gum in Harebrained’s lab. \\n\"\n",
    "            \"As security swarmed, Bugs nonchalantly strolled out, munching his carrot. “Another nutty scheme nipped in the bud,” he quipped.\"\n",
    "            )\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    conversation=conversation,\n",
    "    documents=documents,\n",
    "    add_generation_prompt=True,\n",
    "    chat_template=\"rag\",\n",
    "    return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    )\n",
    "\n",
    "gen_text = tokenizer.decode(gen_tokens[0])\n",
    "print(tokenizer.batch_decode(gen_tokens[:, input_ids.shape[1]:])[0]) # print only the assistant's response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
